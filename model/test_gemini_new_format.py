"""
Test script for the updated Gemini Bottleneck Predictor
Demonstrates the new output format matching inference.py structure
"""

import asyncio
import json
import sys
import os
from datetime import datetime

# Add current directory to path for imports
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from gemini_bottleneck_predictor import GeminiBottleneckPredictor


async def test_gemini_predictor():
    """Test the updated Gemini bottleneck predictor with new format"""
    
    # Sample aircraft data for testing
    test_aircraft = [
        {
            "flight": "DAL123",
            "lat": 40.6413,
            "lon": -73.7781,
            "altitude": "ground",
            "speed": 0,
            "heading": 90
        },
        {
            "flight": "UAL456",
            "lat": 40.6420,
            "lon": -73.7790,
            "altitude": "ground",
            "speed": 0,
            "heading": 180
        },
        {
            "flight": "AAL789",
            "lat": 40.6415,
            "lon": -73.7785,
            "altitude": "ground",
            "speed": 5,
            "heading": 270
        },
        {
            "flight": "JBU101",
            "lat": 40.6425,
            "lon": -73.7795,
            "altitude": 1500,
            "speed": 120,
            "heading": 45
        },
        {
            "flight": "SWA202",
            "lat": 40.6408,
            "lon": -73.7775,
            "altitude": "ground",
            "speed": 0,
            "heading": 0
        }
    ]
    
    print("ğŸ§ª Testing Updated Gemini Bottleneck Predictor...")
    print(f"ğŸ“Š Test data: {len(test_aircraft)} aircraft")
    
    try:
        # Check if API key is available
        import os
        if not os.getenv('GEMINI_API_KEY'):
            print("âš ï¸  GEMINI_API_KEY not set. Using fallback mode.")
            print("   Set your API key: export GEMINI_API_KEY='your-api-key'")
        
        # Initialize predictor
        predictor = GeminiBottleneckPredictor()
        
        # Run prediction
        print("ğŸ¤– Running prediction...")
        result = await predictor.predict_bottlenecks(test_aircraft, "JFK")
        
        # Display results in new format
        print("\nğŸ“‹ PREDICTION RESULTS (New Format):")
        print("=" * 50)
        print(f"Bottleneck ID: {result.bottleneck_id}")
        print(f"Coordinates: {result.coordinates}")
        print(f"Timestamp: {result.timestamp}")
        print(f"Type: {result.type}")
        print(f"Severity: {result.severity}/5")
        print(f"Duration: {result.duration:.1f} minutes")
        print(f"Confidence: {result.confidence:.2f}")
        print(f"Aircraft Count: {result.aircraft_count}")
        
        print(f"\nâœˆï¸  Affected Aircraft:")
        for aircraft in result.aircraft_affected:
            print(f"  - {aircraft['flight_id']} ({aircraft['aircraft_type']})")
            print(f"    Position: {aircraft['position']}")
            print(f"    Time: {aircraft['time']}")
        
        # Convert to JSON format like inference.py
        result_dict = {
            "bottleneck_id": result.bottleneck_id,
            "coordinates": result.coordinates,
            "timestamp": result.timestamp,
            "type": result.type,
            "severity": result.severity,
            "duration": result.duration,
            "confidence": result.confidence,
            "aircraft_count": result.aircraft_count,
            "aircraft_affected": result.aircraft_affected
        }
        
        print(f"\nğŸ“„ JSON Output (inference.py format):")
        print(json.dumps(result_dict, indent=2))
        
        print(f"\nâœ… Test completed successfully!")
        
        return result_dict
        
    except Exception as e:
        print(f"âŒ Test failed: {e}")
        import traceback
        traceback.print_exc()
        return None


def compare_with_inference_format():
    """Compare our output with the inference.py format"""
    
    print("\nğŸ” COMPARISON WITH INFERENCE.PY FORMAT:")
    print("=" * 50)
    
    # Sample from inference.py
    inference_sample = {
        "bottleneck_id": "taxiway_2025-09-19_12:30:00",
        "coordinates": [40.638498, -73.774974],
        "timestamp": "2025-09-19 12:30:00",
        "type": "taxiway",
        "severity": 5,
        "duration": 26.0,
        "confidence": 1.00,
        "aircraft_count": 13,
        "aircraft_affected": [
            {
                "flight_id": "EDV5399",
                "aircraft_type": "B737",
                "position": [40.635436, -73.781156],
                "time": "2025-09-19T12:36:30",
            }
        ]
    }
    
    print("âœ… Required fields match:")
    print("  - bottleneck_id: âœ“")
    print("  - coordinates: âœ“")
    print("  - timestamp: âœ“")
    print("  - type: âœ“")
    print("  - severity: âœ“")
    print("  - duration: âœ“")
    print("  - confidence: âœ“")
    print("  - aircraft_count: âœ“")
    print("  - aircraft_affected: âœ“")
    
    print("\nâœ… aircraft_affected structure matches:")
    print("  - flight_id: âœ“")
    print("  - aircraft_type: âœ“")
    print("  - position: âœ“")
    print("  - time: âœ“")


async def main():
    """Run the test"""
    print("ğŸš€ Updated Gemini Bottleneck Predictor Test\n")
    
    # Run test
    result = await test_gemini_predictor()
    
    # Compare formats
    compare_with_inference_format()
    
    if result:
        print("\nğŸ‰ All tests passed! Format matches inference.py structure.")
    else:
        print("\nğŸ’¥ Some tests failed!")


if __name__ == "__main__":
    asyncio.run(main())
